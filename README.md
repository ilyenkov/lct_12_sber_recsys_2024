# Построение мультимодальной рекомендательной системы для задачи 12 ЛЦТ 2024

**Общая архитектура** решения повторяет предложенную в базовом решении
1) Ноутбуки trx_pyspark_v1_2_train_test и geo_pyspark_v1_2_train_test - считаем по отдельности эмбеддинги для данных по транзакциям и по геолокациям с помощью CoLESModule (Contrastive Learning for Event Sequences) из бибилиотеки pytorch-livestream
2) Ноутбук naive_v1_trx_v1_2_dial_geo_v1_2_new_fea_v4_iter750 - считаем табличные фичи по истории таргетов, транзакций и диалогов, объединяем с эмбеддингами и обучаем CatBoostClassifier:
2.1) эмбеддинги по диалогам усредняем по пользователям (в среднем по 4 диалога на пользователя, то есть для большинства их меньше 4)
2.2) добавляем табличные фичи:
 - сколько раз в предыдущих месяцах встречался каждый из таргетов или любой их них, как давно они встречались
 - в каком из месяцев последний раз встречался каждый из таргетов или люой из них и сколько месяцев прошло с тех пор
 - сколько раз клиент звонил всего и за последний месяц, сколько времени прошло с последнего и среднего звонка
 - сколько у клиента всего было транзакций и сколько за последний месяц, сколько времени прошло с последней и средней транзакции
 - то же самое в разрезе тразакций разных типов ('event_type', 'src_type11', 'dst_type11')
2.3) Всего получается 2 191 фича. Считаем по ним CatBoostClassifier со стратифицированной по отдельности по каждому таргету валидацией с разбиением на 5 фолдов и группировкой по клиентам.

**Подходы к валидации**
1) во время обучения использовалась hold-out валидации (30% трейна по 3 последним месяцам)
2) финальный прогон модели делался по всем данным с 5-фолдовой CV
3) соответствующие файлы train и test всегда объединялись для обучения, чтобы историческая информация о поведении тестовых пользователей тоже использовалась для обучения
Оба варианта валидации показывают высокую корреляцию с лидербордом, так что можно считать, что потенциальный лик данных (для обучения используются данные по другим пользователям за тот же месяц, в котором делается prediction) незначителен.

**Оценка точности модели**
Кросс-валидация с hold-out и без него даёт точность AUC примерно ??? и на публичном лидерборде ???.

**Значимость фич в CatBoostClassifier**
1) Эмбеддинги от транзакций
2) Время со средних и с последних транзакций в разрезе src_type11 и dst_type11
3) Количество транзакций в последний месяц в разрезе event_type, src_type11 и dst_type11
4) Эмбеддинги от геолокаций
5) Эмбеддинги от диалогов

**Не сработавшие фичи и подходы:**
1) эмбеддинги по транзакциям за последний месяц
2) эмбеддинги по диалогам за последний месяц
3) табличные фичи по геолокациям

**Что ещё можно попробовать:**
1) добавить в CoLES модель время с транзакции до отчётной даты - должно улучшить эмбеддинги по транзакциям, но потребует пересчёта каждый месяц, то есть разбиение пользователя на 12 комбинаций пользователь-месяц
2) добавить в CoLES модель день недели и время суток как категориальные фичи (если все event_time даны по местному времени)

**Ресурсы и время обучения:**
1) Ноутбуки trx_pyspark_v1_2_train_test и geo_pyspark_v1_2_train_test работали на 128Гб RAM, 8 CPU, GPU Tesla V100 примерно 10 и 7 часов соответственно
2) Ноутбук naive_v1_trx_v1_2_dial_geo_v1_2_new_fea_v4_iter750 работал на 640Гб RAM, 64CPU примерно 15 часов

**Методы и бибилиотеки**
1) в модели из pytorch-livestream данные подавались с помощью библиотеки pyspark
2) для обработки таблиц использовался polars как более быстрый аналог pandas
2) градиентный бустинг использовался от catboost
3) версии библиотек:
   - catboost==1.2.2
   - pandas==1.4.3
   - numpy==1.26.0
   - polars==0.20.17
   - sklearn==1.3.1
   - torch==1.13.1+cu116
   - pytorch-lightning==2.2.5
   - pytorch-livestream==0.6.0
